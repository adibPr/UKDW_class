{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "Data is taken from https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\n",
    "\n",
    "Some reference:\n",
    "* https://www.aclweb.org/anthology/W03-0423.pdf, \n",
    "* https://towardsdatascience.com/named-entity-recognition-and-classification-with-scikit-learn-f05372f07ba2, \n",
    "* https://mattshomepage.com/articles/2016/May/23/nltk_nec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "tqdm.pandas ()\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>killed</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #      Word  POS Tag\n",
       "0  Sentence: 2  Families  NNS   O\n",
       "1  Sentence: 2        of   IN   O\n",
       "2  Sentence: 2  soldiers  NNS   O\n",
       "3  Sentence: 2    killed  VBN   O\n",
       "4  Sentence: 2        in   IN   O"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data = os.path.abspath ('../../data/ukdw-2')\n",
    "data = pd.read_csv (os.path.join (path_data, 'ner_sample.csv'), encoding='latin')\n",
    "\n",
    "# fill the NaN value with the previously seen value\n",
    "data[\"Sentence #\"] = data[\"Sentence #\"].fillna (method=\"ffill\")\n",
    "data.head (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Tag\n",
      "B-art\n",
      "B-eve\n",
      "B-geo\n",
      "B-gpe\n",
      "B-nat\n",
      "B-org\n",
      "B-per\n",
      "B-tim\n",
      "I-art\n",
      "I-eve\n",
      "I-geo\n",
      "I-gpe\n",
      "I-nat\n",
      "I-org\n",
      "I-per\n",
      "I-tim\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "print (\"Unique Tag\")\n",
    "print (\"\\n\".join (sorted (set (data[\"Tag\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# if you want to analyze person only\n",
    "data['Tag'] = data['Tag'].apply (lambda f: f if f in ('B-per', 'I-per') else 'O')\n",
    "print (\"Unique Tag\")\n",
    "print (\"\\n\".join (sorted (set (data[\"Tag\"]))))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119503/119503 [00:00<00:00, 1486933.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# get prev word\n",
    "data['prev_word'] = data['Word'].shift (periods=1, fill_value='__start__')\n",
    "\n",
    "# add __start__ for each sentence start\n",
    "sentence_list = data['Sentence #'].tolist ()\n",
    "prev_word = data['prev_word'].tolist ()\n",
    "for idx in tqdm (range (1, len (sentence_list))):\n",
    "    if sentence_list[idx-1] != sentence_list[idx]:\n",
    "        prev_word[idx] = '__start__'\n",
    "\n",
    "# reupdate prev_word\n",
    "data['prev_word'] = prev_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>prev_word</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>__start__</td>\n",
       "      <td>{'word': 'Families'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>Families</td>\n",
       "      <td>{'word': 'of'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "      <td>{'word': 'soldiers'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>killed</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>{'word': 'killed'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>killed</td>\n",
       "      <td>{'word': 'in'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #      Word  POS Tag  prev_word               feature\n",
       "0  Sentence: 2  Families  NNS   O  __start__  {'word': 'Families'}\n",
       "1  Sentence: 2        of   IN   O   Families        {'word': 'of'}\n",
       "2  Sentence: 2  soldiers  NNS   O         of  {'word': 'soldiers'}\n",
       "3  Sentence: 2    killed  VBN   O   soldiers    {'word': 'killed'}\n",
       "4  Sentence: 2        in   IN   O     killed        {'word': 'in'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract feature\n",
    "def extract(d):\n",
    "    feature = {\n",
    "        \"word\" : d[\"Word\"]    \n",
    "    }\n",
    "    return feature\n",
    "data[\"feature\"] = data.apply (extract, axis=1)\n",
    "data.head (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a maxent bayes classifier\n",
    "# classifier = nltk.classify.MaxentClassifier.train(data[[\"feature\", \"Tag\"]].values)\n",
    "\n",
    "# create a naive bayes classifier\n",
    "classifier = nltk.classify.NaiveBayesClassifier.train(data[[\"feature\", \"Tag\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    word = 'President'     B-per : O      =    609.7 : 1.0\n",
      "                    word = 'French'        B-gpe : O      =    543.5 : 1.0\n",
      "                    word = 'Pakistan'      B-geo : O      =    516.2 : 1.0\n",
      "                    word = 'Union'         I-org : O      =    390.3 : 1.0\n",
      "                    word = 'the'               O : B-tim  =    332.7 : 1.0\n",
      "                    word = 'Ministry'      I-org : O      =    279.9 : 1.0\n",
      "                    word = 'Prime'         B-per : O      =    262.2 : 1.0\n",
      "                    word = 'U.S.'          B-geo : B-per  =    247.2 : 1.0\n",
      "                    word = 'York'          I-geo : O      =    205.0 : 1.0\n",
      "                    word = 'General'       B-per : O      =    162.3 : 1.0\n",
      "                    word = 'American'      B-gpe : O      =    144.7 : 1.0\n",
      "                    word = '2004'          I-tim : O      =    142.3 : 1.0\n",
      "                    word = 'King'          B-per : O      =    141.6 : 1.0\n",
      "                    word = 'Barack'        I-per : O      =    140.5 : 1.0\n",
      "                    word = 'New'           B-geo : O      =    137.1 : 1.0\n",
      "                    word = 'Tehran'        B-geo : O      =    136.2 : 1.0\n",
      "                    word = 'Senator'       B-per : O      =    126.2 : 1.0\n",
      "                    word = 'Supreme'       B-org : O      =    123.4 : 1.0\n",
      "                    word = 'and'               O : B-tim  =    117.7 : 1.0\n",
      "                    word = 'Iraq'          B-geo : B-gpe  =    115.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# most important feature\n",
    "classifier.show_most_informative_features (20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I-per'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = {\"word\" : \"Obama\"}\n",
    "classifier.classify (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President/B-per Joko/O Widodo/O visit/O Netherlands/B-geo for/O discussing/O global/O warming/O "
     ]
    }
   ],
   "source": [
    "def extract_ner (text):\n",
    "    for t in text.split ():\n",
    "        feat = {\"word\" : t}\n",
    "        print (\"{}/{}\".format (t, classifier.classify (feat)), end=' ')\n",
    "\n",
    "extract_ner (\"President Joko Widodo visit Netherlands for discussing global warming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['predicted'] = data['feature'].apply (classifier.classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# various matrices\n",
    "accuracy = accuracy_score (data['Tag'], data['predicted'])\n",
    "labels = list (set (data['Tag']))\n",
    "precision, recall, fscore, support = precision_recall_fscore_support (data['Tag'], data['predicted'], labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I-tim', 0.024279210925644917),\n",
       " ('B-tim', 0.7874648453194054),\n",
       " ('O', 0.9985449450312567),\n",
       " ('B-org', 0.3798348544111256),\n",
       " ('B-art', 0.0),\n",
       " ('I-nat', 0.0),\n",
       " ('I-eve', 0.0),\n",
       " ('B-per', 0.8242857142857143),\n",
       " ('I-art', 0.0),\n",
       " ('I-per', 0.8811494611900672),\n",
       " ('B-nat', 0.0),\n",
       " ('I-gpe', 0.0),\n",
       " ('B-gpe', 0.9204604918890633),\n",
       " ('I-org', 0.3517915309446254),\n",
       " ('B-eve', 0.0),\n",
       " ('I-geo', 0.43258426966292135),\n",
       " ('B-geo', 0.893049499871762)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec = list (zip (labels, recall))\n",
    "prec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
