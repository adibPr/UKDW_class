{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third parties module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# local module\n",
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "comp.graphics\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.windows.x\n",
      "misc.forsale\n",
      "rec.autos\n",
      "rec.motorcycles\n",
      "rec.sport.baseball\n",
      "rec.sport.hockey\n",
      "sci.crypt\n",
      "sci.electronics\n",
      "sci.med\n",
      "sci.space\n",
      "soc.religion.christian\n",
      "talk.politics.guns\n",
      "talk.politics.mideast\n",
      "talk.politics.misc\n",
      "talk.religion.misc\n",
      "                                                text                 target\n",
      "0  I was wondering if anyone out there could enli...              rec.autos\n",
      "1  A fair number of brave souls who upgraded thei...  comp.sys.mac.hardware\n",
      "2  well folks, my mac plus finally gave up the gh...  comp.sys.mac.hardware\n",
      "3  \\nDo you have Weitek's address/phone number?  ...          comp.graphics\n",
      "4  From article <C5owCB.n3p@world.std.com>, by to...              sci.space\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = load_data ('text')\n",
    "# show some data\n",
    "print ('\\n'.join (np.unique (data['target'])))\n",
    "print (data.head (5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop word and basic preprocessing\n",
    "stopword = nltk.corpus.stopwords.words ('english')\n",
    "punctuation = string.punctuation + '@<?'\n",
    "def preprocessing (text):\n",
    "    # first lowering\n",
    "    text = text.lower ()\n",
    "    # replace punctuation\n",
    "    for punc in punctuation:\n",
    "        text.replace (punc, ' ')\n",
    "    # replace stopwords\n",
    "    words = nltk.word_tokenize (text)\n",
    "    words = [w for w in words if w not in stopword and len (w) >= 3]\n",
    "    \n",
    "    return ' '.join (words)\n",
    "\n",
    "data['token'] = data['text'].apply (preprocessing)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 1000)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF top 1000 --> normalize\n",
    "vectorizer = TfidfVectorizer (max_features=1000)\n",
    "features = vectorizer.fit_transform (data['token'])\n",
    "print (features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=15, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_topics = 15\n",
    "lda = LatentDirichletAllocation (num_topics)\n",
    "lda.fit (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_data = lda.transform (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935.4401122987651\n",
      "Topic 0, centroid : space nasa university launch research\n",
      "1021.9962962031641\n",
      "Topic 1, centroid : sale offer shipping condition asking\n",
      "9412.751473765755\n",
      "Topic 2, centroid : god one would people think\n",
      "519.2503681934141\n",
      "Topic 3, centroid : players play nhl game hockey\n",
      "1641.0559362289637\n",
      "Topic 4, centroid : key chip encryption clipper keys\n",
      "399.5496054455177\n",
      "Topic 5, centroid : dod faq heard company gun\n",
      "4579.578097624305\n",
      "Topic 6, centroid : drive card scsi video monitor\n",
      "8524.037963019511\n",
      "Topic 7, centroid : people would government israel one\n",
      "1355.3594083858213\n",
      "Topic 8, centroid : fax phone price 800 buy\n",
      "748.4031379352612\n",
      "Topic 9, centroid : 00 10 11 20 12\n",
      "5851.116264378948\n",
      "Topic 10, centroid : windows use file program window\n",
      "588.0097988530504\n",
      "Topic 11, centroid : edu widget ftp cs pub\n",
      "393.97684881158256\n",
      "Topic 12, centroid : deleted ground stuff wire ax\n",
      "1665.1554549048603\n",
      "Topic 13, centroid : thanks please anyone mail know\n",
      "9978.372025666404\n",
      "Topic 14, centroid : one car would year like\n"
     ]
    }
   ],
   "source": [
    "sorted_topic = lda.components_.argsort ()[:,::-1]\n",
    "terms = vectorizer.get_feature_names ()\n",
    "for k in range (num_topics):\n",
    "    label = []\n",
    "    for t_idx in sorted_topic[k,:5]:\n",
    "        label.append (terms[t_idx])\n",
    "    print (\"Topic {}, centroid : {}\".format (k, ' '.join (label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01014302 0.0101431  0.85799735 0.01014302 0.01014304 0.01014305\n",
      " 0.01014305 0.01014304 0.01014307 0.01014306 0.01014305 0.01014304\n",
      " 0.01014302 0.01014303 0.01014305]\n",
      "\n",
      "0.9999999999999999\n",
      "\n",
      "14-y-o son usual teenage spotty chin greasy nose bought clearasil face wash ointment think probably enough along usual good diet however get product called dalacin used doctor's-prescription treatment available chemist counter asked couple pharmacists say either acne severe enough dalacin clearasil ok. odd spots teenager nothing serious father n't figure acne going escalate something disfiguring know kids senstitive appearance wary neighbour son wierd malady eventually put overdose vitamin acne treatment want help appropriate treatment son also scaliness around hairline scalp sort teenage cradle cap pointers/advice tried couple anti dandruff shampoos inclined make condition worse better shall bury kid till\n",
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "idx = 31\n",
    "print (mapped_data[idx])\n",
    "print ()\n",
    "print (sum (mapped_data[idx]))\n",
    "print ()\n",
    "print (data.loc[idx, 'token'])\n",
    "print (data.loc[idx, 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
